{"cells":[{"cell_type":"markdown","source":["# CNNs\n","\n","This notebook contains the code needed to train and test the CNNs described in \"Comparing deep learning and concept extraction based methods for patient phenotyping from clinical narratives\"."],"metadata":{"id":"t5MXR4CWwWVw"}},{"cell_type":"markdown","source":["## Preparation\n","\n","First, the necessary libraries are imported. A connection to Google Drive was set up and the working directory was moved to \"DLH project\" (if this folder was shared to you, you will need to make a shortcut to \"DLH project\" to use this code). It was specified that the GPU should be used for training, if one is available, a hyperparameter specifying the number of kernels per n-gram size was set (to 100, as that was the value used in the original paper), and torch was told to not use scientific notation for decimals. The specifications of the GPU were investigated as well. "],"metadata":{"id":"YcbjZKAJwtux"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"839qZ9Xv_UK6"},"outputs":[],"source":["import matplotlib.pyplot as plt \n","import numpy as np\n","import os\n","import pandas as pd\n","# import pycuda.driver as cuda\n","import time\n","import sys\n","import torch\n","import torch.nn as nn\n","import tqdm\n","\n","from prettytable import PrettyTable\n","from sklearn.metrics import *\n","from torch.utils.data import Dataset"]},{"cell_type":"code","source":["# !pip install pycuda"],"metadata":{"id":"oqUVXoQ6j5ik"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # https://medium.com/ai%C2%B3-theory-practice-business/use-gpu-in-your-pytorch-code-676a67faed09\n","# print('__Python VERSION:', sys.version)\n","# print('__pyTorch VERSION:', torch.__version__)\n","# print('__CUDA VERSION', )\n","# from subprocess import call\n","# # call([\"nvcc\", \"--version\"]) does not work\n","# ! nvcc --version\n","# print('__CUDNN VERSION:', torch.backends.cudnn.version())\n","# print('__Number CUDA Devices:', torch.cuda.device_count())\n","# print('__Devices')\n","# # call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n","# print('Active CUDA Device: GPU', torch.cuda.current_device())\n","# print ('Available devices ', torch.cuda.device_count())\n","# print ('Current cuda device ', torch.cuda.current_device())"],"metadata":{"id":"-zZLFbStjsvp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cuda.init()\n","# ## Get Id of default device\n","# torch.cuda.current_device() # Tesla T4 with standard GPU on Google drive\n","# # 0\n","# cuda.Device(0).name() # '0' is the id of your GPU"],"metadata":{"id":"Eif9bf6mlvLP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kernels_per_n_gram_size = 100"],"metadata":{"id":"RWCKuXsZwtCJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xhTTFyn3j0d"},"outputs":[],"source":["# For better printing\n","torch.set_printoptions(sci_mode=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6222,"status":"ok","timestamp":1682033561796,"user":{"displayName":"Jeremy Bao","userId":"06505276041201628013"},"user_tz":300},"id":"M8HyvIDT_68m","outputId":"0927b917-cc3f-44b7-eb8d-459156b06dc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2zm_19OF_8OP"},"outputs":[],"source":["os.chdir(\"/content/drive/MyDrive/DLH project\")"]},{"cell_type":"code","source":["device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMZancapewOt","executionInfo":{"status":"ok","timestamp":1682033561798,"user_tz":300,"elapsed":8,"user":{"displayName":"Jeremy Bao","userId":"06505276041201628013"}},"outputId":"56973c95-d65d-4b11-c59f-8794bcd82fc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}]},{"cell_type":"markdown","source":["## Loading the data\n","Here, we load the data to be used. labelled_corpus_df contains the labels and the cleaned text for each of the discharge summaries we will use, and study_corpus_tensor contains the representationf of those documents, with study_corpus_tensor[i, :, :] representing the i-th document and study_corpus_tensor[i, j, :] containing the word embedding representing the j-th word in the i-th document.\n","\n","The data is put into a custom dataset object for use in PyTorch."],"metadata":{"id":"LbnYPowayPGS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYhxffDbABuO"},"outputs":[],"source":["labelled_corpus_df = pd.read_csv(\"labelled_corpus_df.csv\", index_col = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1682033562196,"user":{"displayName":"Jeremy Bao","userId":"06505276041201628013"},"user_tz":300},"id":"2QZZWU08Kkip","outputId":"9e8acc98-b22f-496f-878d-6708aec081b8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    HADM_ID  SUBJECT_ID  Advanced.Cancer  Advanced.Heart.Disease  \\\n","0  118003.0        3644                0                       0   \n","\n","   Advanced.Lung.Disease  Chronic.Neurological.Dystrophies  \\\n","0                      0                                 0   \n","\n","   Chronic.Pain.Fibromyalgia  Alcohol.Abuse  Other.Substance.Abuse  Obesity  \\\n","0                          1              0                      0        0   \n","\n","   Schizophrenia.and.other.Psychiatric.Disorders  Depression  \\\n","0                                              0           1   \n","\n","                                        Cleaned Text  \n","0  admission date 2200 4 7 discharge date 2200 4 ...  "],"text/html":["\n","  <div id=\"df-b17cef1d-7df9-4bb7-b8a9-b263d506cef9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HADM_ID</th>\n","      <th>SUBJECT_ID</th>\n","      <th>Advanced.Cancer</th>\n","      <th>Advanced.Heart.Disease</th>\n","      <th>Advanced.Lung.Disease</th>\n","      <th>Chronic.Neurological.Dystrophies</th>\n","      <th>Chronic.Pain.Fibromyalgia</th>\n","      <th>Alcohol.Abuse</th>\n","      <th>Other.Substance.Abuse</th>\n","      <th>Obesity</th>\n","      <th>Schizophrenia.and.other.Psychiatric.Disorders</th>\n","      <th>Depression</th>\n","      <th>Cleaned Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>118003.0</td>\n","      <td>3644</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>admission date 2200 4 7 discharge date 2200 4 ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b17cef1d-7df9-4bb7-b8a9-b263d506cef9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b17cef1d-7df9-4bb7-b8a9-b263d506cef9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b17cef1d-7df9-4bb7-b8a9-b263d506cef9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}],"source":["labelled_corpus_df.head(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQBj7eg2ADJ6"},"outputs":[],"source":["# Takes some time (< 1 minute)\n","study_corpus_tensor = torch.load(\"embedded_docs.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1682033573334,"user":{"displayName":"Jeremy Bao","userId":"06505276041201628013"},"user_tz":300},"id":"a4OH-PKzKzYz","outputId":"6147f29f-411c-4a7d-a9d6-9236ec925fed"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1341, 5434, 100])"]},"metadata":{},"execution_count":14}],"source":["study_corpus_tensor.shape"]},{"cell_type":"code","source":["study_corpus_tensor.device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aV1mDB7lg3wK","executionInfo":{"status":"ok","timestamp":1682033573335,"user_tz":300,"elapsed":16,"user":{"displayName":"Jeremy Bao","userId":"06505276041201628013"}},"outputId":"efae171a-61ad-4505-ae75-85dc5c339a78"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["study_corpus_tensor = study_corpus_tensor.to(device)\n","print(study_corpus_tensor.device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XM63U-Ahg_Hz","executionInfo":{"status":"ok","timestamp":1682033577649,"user_tz":300,"elapsed":4323,"user":{"displayName":"Jeremy Bao","userId":"06505276041201628013"}},"outputId":"296accee-8f73-49c1-afd9-44a1f35aadc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1682033577650,"user":{"displayName":"Jeremy Bao","userId":"06505276041201628013"},"user_tz":300},"id":"nCI7bGV5LClT","outputId":"a85df6ce-e490-472f-fc36-776fd659ea18"},"outputs":[{"output_type":"stream","name":"stdout","text":["100\n"]}],"source":["embedding_vector_size = study_corpus_tensor.shape[2]\n","print(embedding_vector_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eN5Xc9BXAH8q"},"outputs":[],"source":["class CustomDatasetEmbedded(Dataset):\n","    def __init__(self, corpus_tensor, labels):\n","        \"\"\"\n","        Store the corpus (of shape num_docs by max_num_words_per_doc by size_of_word embedding) \n","        labels (for a single target variable)\n","        \"\"\"\n","\n","        self.x = corpus_tensor\n","        self.y = labels\n","\n","    def __len__(self):\n","\n","        \"\"\"\n","        Return the number of documents\n","        \"\"\"\n","        return len(self.y)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Return one document (represented as a tensor, with each row being the embedding for one word in that document),\n","        and its label (whether the patient described has or does not have some phenotype)\n","        \"\"\"\n","        return (self.x[index, :, :], self.y[index])"]},{"cell_type":"code","source":["depression_y = torch.tensor(labelled_corpus_df[\"Depression\"]).to(device)\n","print(depression_y.device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9Xlapy6hPay","executionInfo":{"status":"ok","timestamp":1682033577652,"user_tz":300,"elapsed":38,"user":{"displayName":"Jeremy Bao","userId":"06505276041201628013"}},"outputId":"6b163c3c-ea13-4ecf-e6c7-4c6e75266176"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eT1rqfVcAK3N"},"outputs":[],"source":["depression_dataset = CustomDatasetEmbedded(study_corpus_tensor, depression_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qrgYBHoXKUj1"},"outputs":[],"source":["train_dataset, test_dataset = torch.utils.data.random_split(depression_dataset, [0.8, 0.2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNXeln1JKXoL"},"outputs":[],"source":["# len(train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i6pONbZcKYbl"},"outputs":[],"source":["# len(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"npAtqpw5KaB7"},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True) # Batch size?\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32)"]},{"cell_type":"markdown","source":["# CNN\n","This class allows you to create CNNs for predicting patient characterstics based on discharge summaries as described in the paper being replicated. n_gram_sizes must be a list which can contain the integers 1, 2, 3, 4, and/or 5. The CNN created will consider n-grams of the sizes specified in n_gram_sizes when looking at discharge summaries. Each CNN is a binary classifier which predicts if a patient has or lacks a single condition."],"metadata":{"id":"32FnAxDNyozI"}},{"cell_type":"code","source":["class CNN_n_gram(nn.Module):\n","    def __init__(self, n_gram_sizes):\n","        super(CNN_n_gram, self).__init__()\n","\n","        self.n_gram_sizes = n_gram_sizes\n","        num_sizes = 0\n","\n","        if 1 in self.n_gram_sizes:\n","            self.conv1 = nn.Conv2d(in_channels = 1,\n","                                  out_channels = kernels_per_n_gram_size,\n","                                  kernel_size = (1, embedding_vector_size),\n","                                  stride = 1,\n","                                  padding = 0)\n","            torch.nn.init.uniform_(self.conv1.weight, -0.01, 0.01)\n","            torch.nn.init.zeros_(self.conv1.bias)\n","\n","            # each kernel's feature map is condensed to a single value\n","            conv1_output_height = study_corpus_tensor.shape[1] + 1 - 1\n","            self.pool1 = nn.MaxPool2d(kernel_size = (conv1_output_height, 1))\n","            num_sizes += 1\n","\n","        if 2 in self.n_gram_sizes:\n","            self.conv2 = nn.Conv2d(in_channels = 1,\n","                                  out_channels = kernels_per_n_gram_size,\n","                                  kernel_size = (2, embedding_vector_size),\n","                                  stride = 1,\n","                                  padding = 0)\n","            torch.nn.init.uniform_(self.conv2.weight, -0.01, 0.01)\n","            torch.nn.init.zeros_(self.conv2.bias)\n","\n","            # each kernel's feature map is condensed to a single value\n","            conv2_output_height = study_corpus_tensor.shape[1] + 1 - 2\n","            self.pool2 = nn.MaxPool2d(kernel_size = (conv2_output_height, 1))\n","            num_sizes += 1\n","\n","        if 3 in self.n_gram_sizes:\n","            self.conv3 = nn.Conv2d(in_channels = 1,\n","                                  out_channels = kernels_per_n_gram_size,\n","                                  kernel_size = (3, embedding_vector_size),\n","                                  stride = 1,\n","                                  padding = 0)\n","            torch.nn.init.uniform_(self.conv3.weight, -0.01, 0.01)\n","            torch.nn.init.zeros_(self.conv3.bias)\n","\n","            # each kernel's feature map is condensed to a single value\n","            conv3_output_height = study_corpus_tensor.shape[1] + 1 - 3\n","            self.pool3 = nn.MaxPool2d(kernel_size = (conv3_output_height, 1))\n","            num_sizes += 1\n","\n","        if 4 in self.n_gram_sizes:\n","            self.conv4 = nn.Conv2d(in_channels = 1,\n","                                  out_channels = kernels_per_n_gram_size,\n","                                  kernel_size = (4, embedding_vector_size),\n","                                  stride = 1,\n","                                  padding = 0)\n","            torch.nn.init.uniform_(self.conv4.weight, -0.01, 0.01)\n","            torch.nn.init.zeros_(self.conv4.bias)\n","\n","            # each kernel's feature map is condensed to a single value\n","            conv4_output_height = study_corpus_tensor.shape[1] + 1 - 4\n","            self.pool4 = nn.MaxPool2d(kernel_size = (conv4_output_height, 1))\n","            num_sizes += 1\n","\n","        if 5 in self.n_gram_sizes:\n","            self.conv5 = nn.Conv2d(in_channels = 1,\n","                                  out_channels = kernels_per_n_gram_size,\n","                                  kernel_size = (5, embedding_vector_size),\n","                                  stride = 1,\n","                                  padding = 0)\n","            torch.nn.init.uniform_(self.conv5.weight, -0.01, 0.01)\n","            torch.nn.init.zeros_(self.conv5.bias)\n","\n","            # each kernel's feature map is condensed to a single value\n","            conv5_output_height = study_corpus_tensor.shape[1] + 1 - 5\n","            self.pool5 = nn.MaxPool2d(kernel_size = (conv5_output_height, 1))\n","            num_sizes += 1\n","\n","        assert num_sizes > 0\n","\n","        self.do = nn.Dropout(p = 0.5) \n","\n","        self.fc = nn.Linear(kernels_per_n_gram_size * num_sizes, 2) # Input size. 300, for 300 filters here.\n","        torch.nn.init.normal_(self.fc.weight, 0.01)\n","        torch.nn.init.zeros_(self.fc.bias)\n","\n","        self.activation = nn.LogSoftmax(dim = 1) # Called on tensor of shape [batch_size, 2]\n","        \n","    def forward(self, x):\n","        # Add an extra dimension, because nn.Conv2d takes an input of (batch_size, number of channels, height of input, width of input)\n","        # and not (batch_size, height of input, width of input)\n","        x = torch.unsqueeze(x, dim = 1)\n","\n","        list_of_convolutional_outputs = []\n","\n","        if 1 in self.n_gram_sizes:\n","            x1 = self.conv1(x)\n","            x1 = torch.relu(x1) # Point of this, given the max pooling?\n","            x1 = self.pool1(x1)\n","            list_of_convolutional_outputs.append(x1)\n","        \n","        if 2 in self.n_gram_sizes:\n","            x2 = self.conv2(x)\n","            x2 = torch.relu(x2)\n","            x2 = self.pool2(x2)\n","            list_of_convolutional_outputs.append(x2)\n","        \n","        if 3 in self.n_gram_sizes:\n","            x3 = self.conv3(x)\n","            x3 = torch.relu(x3)\n","            x3 = self.pool3(x3)\n","            list_of_convolutional_outputs.append(x3)\n","\n","        if 4 in self.n_gram_sizes:\n","            x4 = self.conv4(x)\n","            x4 = torch.relu(x4)\n","            x4 = self.pool4(x4)\n","            list_of_convolutional_outputs.append(x4)\n","        \n","        if 5 in self.n_gram_sizes:\n","            x5 = self.conv5(x)\n","            x5 = torch.relu(x5)\n","            x5 = self.pool5(x5)\n","            list_of_convolutional_outputs.append(x5)\n","\n","        # Combine the results of applying differently sized kernels in parallel\n","        x = torch.cat(list_of_convolutional_outputs, dim = 1)\n","\n","        x = self.do(x)\n","\n","        x = torch.flatten(x, start_dim = 1)\n","        \n","        x = self.fc(x)\n","\n","        x = self.activation(x)\n","\n","        return x"],"metadata":{"id":"tt5WMcLvvkOh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x5RKQeiOMSy8"},"outputs":[],"source":["# cnn_1_gram_model = CNN_n_gram([1]).to(device)\n","# print(cnn_1_gram_model)\n","# cnn_1_2_gram_model = CNN_n_gram([1, 2]).to(device)\n","# print(cnn_1_2_gram_model)\n","# cnn_1_2_3_gram_model = CNN_n_gram([1, 2, 3]).to(device)\n","# print(cnn_1_2_3_gram_model)"]},{"cell_type":"code","source":["# for name, param in cnn_1_2_3_gram_model.named_parameters():\n","#     print(name)\n","#     print(param.shape)"],"metadata":{"id":"MVV4DE_FlM90"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_conv = nn.Conv2d(in_channels = 1,\n","#                       out_channels = 100,\n","#                       kernel_size = (2, 100),\n","#                       stride = 1,\n","#                       padding = 0)\n","# for name, param in test_conv.named_parameters():\n","#     if name.endswith(\"weight\"):\n","#         print(torch.linalg.vector_norm(param, dim = (1, 2, 3)))\n","#         print(torch.linalg.vector_norm(param, dim = (1, 2, 3)).shape)"],"metadata":{"id":"YdlUhV9Tmwnp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DitIhtj-Oei6"},"outputs":[],"source":["# # This loss function was specified in main.lua within the GitHub repository provided by the authors of the original study\n","# # local criterion = nn.ClassNLLCriterion()\n","# criterion = nn.modules.loss.NLLLoss() # CrossEntropyLoss() doesn't help\n","\n","# # Adadelta was specified in a PDF file attached to the original paper\n","# # The hyperparameters for the optimizer are specified in trainer.lua from the GitHub repository provided by the authors of the original study\n","# optimizer = torch.optim.Adadelta(cnn_1_2_3_gram_model.parameters(), rho = 0.95, eps = 1e-6)"]},{"cell_type":"code","source":["# # Normalize the weights going into each output in the FC layer to 3?\n","# test_tensor = torch.tensor([[1., 2., 3.],\n","#                             [4., 5., 6.]])\n","# # norms = torch.linalg.vector_norm(test_tensor, dim = 1, keepdim = True)\n","# norms = torch.linalg.vector_norm(test_tensor, keepdim = True)\n","# print(norms)\n","# test_tensor = 3 * test_tensor / norms\n","# print(test_tensor)\n","# # print(torch.linalg.vector_norm(test_tensor, dim = 1, keepdim = True))\n","# print(torch.linalg.vector_norm(test_tensor, keepdim = True))"],"metadata":{"id":"oYQTrCTnc3aa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This function is responsible for training CNNs. It takes in a CNN, a training dataloader, the number of epochs of training to complete, an optmizer, and a loss function, and returns the trained model.\n","\n","You can uncomment the line with tqdm in it to see the progress within each loop (it is currently replaced with a line without tqdm, as printing that when training 60 different CNNs would be excessively verbose)."],"metadata":{"id":"nj5HJFNPzO7_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RfspEHcP3Dm"},"outputs":[],"source":["# From main.lua in the provided code:\n","# cmd:option('-epochs', 20, 'Number of training epochs')\n","# 20 is the default\n","n_epochs = 20\n","\n","# From HW3 CNN\n","def train_model(model, train_dataloader, n_epoch, optimizer, criterion):\n","    \"\"\"\n","    :param model: A CNN model\n","    :param train_dataloader: the DataLoader of the training data\n","    :param n_epoch: number of epochs to train\n","    :return:\n","        model: trained model\n","    \"\"\"\n","    model.train() # prep model for training\n","    \n","    \n","    for epoch in range(n_epoch):\n","        curr_epoch_loss = []\n","        # For testing\n","        loader_index = 0\n","        # for x, y in tqdm.tqdm(train_dataloader):\n","        for x, y in train_dataloader:\n","            \"\"\"\n","            TODO: Within the loop, do the normal training procedures:\n","                   pass the input through the model\n","                   pass the output through loss_func to compute the loss (name the variable as *loss*)\n","                   zero out currently accumulated gradient, use loss.basckward to backprop the gradients, then call optimizer.step\n","            \"\"\"\n","\n","            # print(x.shape) # torch.Size([32, 5434, 100])\n","            # print(y.shape) # torch.Size([32])\n","            # raise NotImplementedError\n","\n","            # your code here\n","            # FROM HOMEWORK 2\n","            \"\"\" Step 1. clear gradients \"\"\"\n","            optimizer.zero_grad()\n","            \"\"\" \n","            TODO: Step 2. perform forward pass using `model`, save the output to y_hat;\n","                  Step 3. calculate the loss using `criterion`, save the output to loss.\n","            \"\"\"\n","\n","            y_hat = model(x)\n","            loss = criterion(y_hat, y)\n","\n","            # print(y_hat)\n","            # print(y)\n","            # raise NotImplementedError\n","\n","            \"\"\" Step 4. backward pass \"\"\"\n","            loss.backward()\n","            \"\"\" Step 5. optimization \"\"\"\n","            optimizer.step()\n","\n","            # NORMALIZE HERE???\n","            # Linear layer's weights (for unigram CNN) are of size [2, 100]\n","            # Normalize each of the two rows to a L2 norm of 3?\n","            norms = torch.linalg.vector_norm(model.fc.weight, dim = 1, keepdim = True) #keepdim = True)\n","            # norms.to(device)\n","            model.fc.weight = torch.nn.Parameter((3 * model.fc.weight) / (norms + 1e-7)) # LIKE SO????\n","\n","            \"\"\" Step 6. record loss \"\"\"\n","            curr_epoch_loss.append(loss.cpu().data.numpy())\n","\n","            # print(torch.sum(torch.max(y_hat, 1).indices) / len(y))\n","\n","            # if epoch == n_epochs - 1: # and loader_index == 0: #and loader_index == 33:\n","                # print(y_hat)\n","                # print(y)\n","                # print(torch.max(y_hat, 1).indices) # NOT RETURNING ALL 0s during training??????\n","                # print(torch.sum(torch.max(y_hat, 1).indices) / len(y))\n","            loader_index += 1\n","\n","        # print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kc081MWSowkJ"},"outputs":[],"source":["# start_time = time.time()\n","# cnn_1_2_3_gram_model = train_model(model = cnn_1_2_3_gram_model,\n","#                                   train_dataloader = train_loader,\n","#                                   n_epoch = n_epochs,\n","#                                   optimizer = optimizer,\n","#                                   criterion = criterion)\n","# end_time = time.time()\n","# print()\n","# print(end_time - start_time)"]},{"cell_type":"markdown","source":["This function evaluates a trained model on the data present within a test dataloader. It returns the true labels, predicted labels, and output of the CNN corresponding to the 1 class (corresponding to the patient having the condition)."],"metadata":{"id":"hZapF4ij_sKa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"u4F4RyV21kNM"},"outputs":[],"source":["# From HW3 CNN\n","def eval_model(model, dataloader):\n","    model.eval()\n","    Y_pred  = []\n","    Y_true  = []\n","    Y_score = []\n","    with torch.no_grad():\n","        for x, y in dataloader:\n","            # your code here\n","            Y_true.append(y)\n","            \n","            y_hat = model(x)\n","            # print(torch.max(y_hat, 1).indices)\n","            \n","            # Y_score.append(torch.exp(y_hat[:, 1]))\n","            Y_score.append(y_hat[:, 1])\n","\n","            # print(y_hat[:, 1])\n","            # print(y)\n","            # raise NotImplementedError\n","\n","            # https://campuswire.com/c/G902DEAF1/feed/823\n","            # Return class with higher probability\n","            Y_pred.append(torch.max(y_hat, 1).indices)\n","            \n","    #         raise NotImplementedError\n","\n","    Y_score = [y_score.to(\"cpu\") for y_score in Y_score]\n","    Y_pred  = [y_pred.to(\"cpu\")  for y_pred  in Y_pred]\n","    Y_true  = [y_true.to(\"cpu\")  for y_true  in Y_true]\n","\n","    Y_score = np.concatenate(Y_score, axis = 0)    \n","    Y_pred  = np.concatenate(Y_pred,  axis=0)\n","    Y_true  = np.concatenate(Y_true,  axis=0)\n","\n","\n","    return Y_score, Y_pred, Y_true"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79LEsajQ1vXX"},"outputs":[],"source":["# y_score, y_pred, y_true = eval_model(cnn_1_2_3_gram_model, test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iIIj8cy212VW"},"outputs":[],"source":["# print(\"Predicted percent of patients that have the condition:\", np.sum(y_pred) / len(y_pred)) # Seed = 4 -> all positive????\n","# print(\"Actual percent of patients that have the condition:\", np.sum(y_true) / len(y_true))\n","# print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n","# print(\"Precision:\", precision_score(y_true, y_pred))\n","# print(\"Recall:\", recall_score(y_true, y_pred))\n","# print(\"F1 Score:\", f1_score(y_true, y_pred))\n","# print(\"AUC:\", roc_auc_score(y_true, y_score))"]},{"cell_type":"code","source":["# plt.boxplot(y_score)\n","# plt.title(\"Seed = \" + str(seed))\n","# plt.show()"],"metadata":{"id":"Dj7Pend9DaXh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for x, y in train_loader:\n","#     print(torch.sum(y))"],"metadata":{"id":"oXT2uF0iqJZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for x, y in test_loader:\n","#     print(torch.sum(y))"],"metadata":{"id":"HJ1m_yYUqO2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # From https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325/23?page=2\n","# def count_parameters(model):\n","#     table = PrettyTable([\"Modules\", \"Parameters\"])\n","#     total_params = 0\n","#     for name, parameter in model.named_parameters():\n","#         if not parameter.requires_grad: \n","#             continue\n","#         param = parameter.numel()\n","#         table.add_row([name, param])\n","#         total_params+=param\n","#     print(table)\n","#     print(f\"Total Trainable Params: {total_params}\")\n","#     return total_params\n","\n","# count_parameters(cnn_1_gram_model)"],"metadata":{"id":"4gVlfr04NOFx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Here, we figure out the name of the file to store results to."],"metadata":{"id":"pAKtuSyf_6wD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_index_results_file = 0\n","for filename in os.listdir():\n","    filename_without_type = filename.split(\".\")[0]\n","    if filename_without_type.startswith(\"results_\"):\n","        index = int(filename_without_type[8:])\n","        if index > max_index_results_file:\n","            max_index_results_file = index\n","\n","new_file_name = \"results_\" + str(max_index_results_file + 1) + \".txt\"\n","print(new_file_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TbSBiIxovBVk","executionInfo":{"status":"ok","timestamp":1682033577661,"user_tz":300,"elapsed":28,"user":{"displayName":"Jeremy Bao","userId":"06505276041201628013"}},"outputId":"97814324-b34a-46de-e0dc-a424bae47590"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["results_3.txt\n"]}]},{"cell_type":"markdown","source":["This function trains a CNN which considers the n-gram sizes described in the list n_gram_sizes for detecting the provided condition. You must provide a training dataloader, test dataloader, the name of the file to store results to, the device to use for training, and the number of epochs of training to perform.\n","\n","It will both print and save to the indicated file information about training time and performance."],"metadata":{"id":"lumB2LnhACz-"}},{"cell_type":"code","source":["def train_test_model(n_gram_sizes, condition, train_loader, test_loader, output_file, device, n_epochs):\n","    which_model = str(n_gram_sizes) + \"-gram CNN for \" + condition\n","    print(which_model)\n","    output_file.write(which_model + \"\\n\")\n","\n","    model = CNN_n_gram(n_gram_sizes).to(device)\n","\n","    criterion = nn.modules.loss.NLLLoss()\n","\n","    optimizer = torch.optim.Adadelta(model.parameters(), rho = 0.95, eps = 1e-6)\n","\n","    start_time = time.time()\n","    model = train_model(model = model,\n","                        train_dataloader = train_loader,\n","                        n_epoch = n_epochs,\n","                        optimizer = optimizer,\n","                        criterion = criterion)\n","    end_time = time.time()\n","    training_time_statement = \"Training time: \" + str(end_time - start_time) + \" seconds\"\n","    print(training_time_statement)\n","    output_file.write(training_time_statement + \"\\n\")\n","\n","    y_score, y_pred, y_true = eval_model(model, test_loader)\n","\n","    predicted_positive_statement = \"Predicted percent of patients that have the condition: \" + str(np.sum(y_pred) / len(y_pred))\n","    print(predicted_positive_statement)\n","    output_file.write(predicted_positive_statement + \"\\n\")\n","\n","    actual_positive_statement = \"Actual percent of patients that have the condition: \" + str(np.sum(y_true) / len(y_true))\n","    print(actual_positive_statement)\n","    output_file.write(actual_positive_statement + \"\\n\")\n","\n","    accuracy_statement = \"Accuracy: \" + str(accuracy_score(y_true, y_pred))\n","    print(accuracy_statement)\n","    output_file.write(accuracy_statement + \"\\n\")\n","\n","    precision_statement = \"Precision: \" + str(precision_score(y_true, y_pred))\n","    print(precision_statement)\n","    output_file.write(precision_statement + \"\\n\")\n","\n","    recall_statement = \"Recall: \" + str(recall_score(y_true, y_pred))\n","    print(recall_statement)\n","    output_file.write(recall_statement + \"\\n\")\n","\n","    f1_statement = \"F1 Score: \" + str(f1_score(y_true, y_pred))\n","    print(f1_statement)\n","    output_file.write(f1_statement + \"\\n\")\n","\n","    auc_statement = \"AUC: \" + str(roc_auc_score(y_true, y_score))\n","    print(auc_statement)\n","    output_file.write(auc_statement + \"\\n\")\n","\n","    print()\n","    output_file.write(\"\\n\")"],"metadata":{"id":"QhqZBtk5_LnJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here, we train and test 6 models considering different sets of n-grams for each of the 10 conditions."],"metadata":{"id":"Er2Rn7AyAR-F"}},{"cell_type":"code","source":["file = open(new_file_name, 'a')\n","\n","seed =  3\n","torch.manual_seed(seed)\n","\n","# advanced or metastatic cancer, advanced heart disease, advanced lung disease, chronic neurologic dystrophies, chronic pain, alcohol abuse, substance abuse, obesity, psychiatric disorders, or depression.\n","all_conditions = [\"Advanced.Cancer\",\n","                  \"Advanced.Heart.Disease\",\n","                  \"Advanced.Lung.Disease\",\n","                  \"Chronic.Neurological.Dystrophies\",\n","                  \"Chronic.Pain.Fibromyalgia\",\n","                  \"Alcohol.Abuse\",\n","                  \"Other.Substance.Abuse\",\n","                  \"Obesity\",\n","                  \"Schizophrenia.and.other.Psychiatric.Disorders\",\n","                  \"Depression\"]\n","\n","for condition in all_conditions:\n","    labels = torch.tensor(labelled_corpus_df[condition]).to(device)\n","\n","    dataset = CustomDatasetEmbedded(study_corpus_tensor, labels)\n","\n","    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n","\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True) # Batch size?\n","    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32)\n","\n","    train_test_model(n_gram_sizes = [1],\n","                     condition = condition,\n","                     train_loader = train_loader,\n","                     test_loader = test_loader,\n","                     output_file = file,\n","                     device = device,\n","                     n_epochs = n_epochs)\n","    train_test_model(n_gram_sizes = [1, 2],\n","                     condition = condition,\n","                     train_loader = train_loader,\n","                     test_loader = test_loader,\n","                     output_file = file,\n","                     device = device,\n","                     n_epochs = n_epochs)\n","    train_test_model(n_gram_sizes = [1, 2, 3],\n","                     condition = condition,\n","                     train_loader = train_loader,\n","                     test_loader = test_loader,\n","                     output_file = file,\n","                     device = device,\n","                     n_epochs = n_epochs)\n","    train_test_model(n_gram_sizes = [1, 2, 3, 4],\n","                     condition = condition,\n","                     train_loader = train_loader,\n","                     test_loader = test_loader,\n","                     output_file = file,\n","                     device = device,\n","                     n_epochs = n_epochs)\n","    train_test_model(n_gram_sizes = [1, 2, 3, 4, 5],\n","                     condition = condition,\n","                     train_loader = train_loader,\n","                     test_loader = test_loader,\n","                     output_file = file,\n","                     device = device,\n","                     n_epochs = n_epochs)\n","    train_test_model(n_gram_sizes = [2, 3, 4, 5],\n","                     condition = condition,\n","                     train_loader = train_loader,\n","                     test_loader = test_loader,\n","                     output_file = file,\n","                     device = device,\n","                     n_epochs = n_epochs)\n","\n","file.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bk2IF91qsp1D","executionInfo":{"status":"ok","timestamp":1682038147164,"user_tz":300,"elapsed":4533880,"user":{"displayName":"Jeremy Bao","userId":"06505276041201628013"}},"outputId":"b7337f56-8efd-4ffc-b1ae-83168d3aa64e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1]-gram CNN for Advanced.Cancer\n","Training time: 16.104912757873535 seconds\n","Predicted percent of patients that have the condition: 0.09328358208955224\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.9477611940298507\n","Precision: 0.76\n","Recall: 0.7037037037037037\n","F1 Score: 0.7307692307692308\n","AUC: 0.9329952358998003\n","\n","[1, 2]-gram CNN for Advanced.Cancer\n","Training time: 22.6281635761261 seconds\n","Predicted percent of patients that have the condition: 0.007462686567164179\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.9067164179104478\n","Precision: 1.0\n","Recall: 0.07407407407407407\n","F1 Score: 0.13793103448275862\n","AUC: 0.9661902566466882\n","\n","[1, 2, 3]-gram CNN for Advanced.Cancer\n","Training time: 59.80095553398132 seconds\n","Predicted percent of patients that have the condition: 0.05970149253731343\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.9514925373134329\n","Precision: 0.9375\n","Recall: 0.5555555555555556\n","F1 Score: 0.6976744186046512\n","AUC: 0.9684186260949746\n","\n","[1, 2, 3, 4]-gram CNN for Advanced.Cancer\n","Training time: 101.2483274936676 seconds\n","Predicted percent of patients that have the condition: 0.014925373134328358\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.9067164179104478\n","Precision: 0.75\n","Recall: 0.1111111111111111\n","F1 Score: 0.19354838709677416\n","AUC: 0.9730290456431535\n","\n","[1, 2, 3, 4, 5]-gram CNN for Advanced.Cancer\n","Training time: 132.52853274345398 seconds\n","Predicted percent of patients that have the condition: 0.10820895522388059\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.9552238805970149\n","Precision: 0.7586206896551724\n","Recall: 0.8148148148148148\n","F1 Score: 0.7857142857142857\n","AUC: 0.9634240049177808\n","\n","[2, 3, 4, 5]-gram CNN for Advanced.Cancer\n","Training time: 123.32019352912903 seconds\n","Predicted percent of patients that have the condition: 0.07462686567164178\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.9514925373134329\n","Precision: 0.85\n","Recall: 0.6296296296296297\n","F1 Score: 0.723404255319149\n","AUC: 0.9721838020593208\n","\n","[1]-gram CNN for Advanced.Heart.Disease\n","Training time: 9.594995975494385 seconds\n","Predicted percent of patients that have the condition: 0.19402985074626866\n","Actual percent of patients that have the condition: 0.11940298507462686\n","Accuracy: 0.8432835820895522\n","Precision: 0.40384615384615385\n","Recall: 0.65625\n","F1 Score: 0.5000000000000001\n","AUC: 0.8891684322033898\n","\n","[1, 2]-gram CNN for Advanced.Heart.Disease\n","Training time: 23.61349868774414 seconds\n","Predicted percent of patients that have the condition: 0.033582089552238806\n","Actual percent of patients that have the condition: 0.11940298507462686\n","Accuracy: 0.8843283582089553\n","Precision: 0.5555555555555556\n","Recall: 0.15625\n","F1 Score: 0.24390243902439024\n","AUC: 0.9145921610169492\n","\n","[1, 2, 3]-gram CNN for Advanced.Heart.Disease\n","Training time: 60.15009260177612 seconds\n","Predicted percent of patients that have the condition: 0.05223880597014925\n","Actual percent of patients that have the condition: 0.11940298507462686\n","Accuracy: 0.9029850746268657\n","Precision: 0.7142857142857143\n","Recall: 0.3125\n","F1 Score: 0.43478260869565216\n","AUC: 0.9368379237288136\n","\n","[1, 2, 3, 4]-gram CNN for Advanced.Heart.Disease\n","Training time: 101.14070200920105 seconds\n","Predicted percent of patients that have the condition: 0.22388059701492538\n","Actual percent of patients that have the condition: 0.11940298507462686\n","Accuracy: 0.8582089552238806\n","Precision: 0.45\n","Recall: 0.84375\n","F1 Score: 0.5869565217391305\n","AUC: 0.9206832627118644\n","\n","[1, 2, 3, 4, 5]-gram CNN for Advanced.Heart.Disease\n","Training time: 132.47803497314453 seconds\n","Predicted percent of patients that have the condition: 0.16417910447761194\n","Actual percent of patients that have the condition: 0.11940298507462686\n","Accuracy: 0.8955223880597015\n","Precision: 0.5454545454545454\n","Recall: 0.75\n","F1 Score: 0.631578947368421\n","AUC: 0.9314088983050848\n","\n","[2, 3, 4, 5]-gram CNN for Advanced.Heart.Disease\n","Training time: 123.31731462478638 seconds\n","Predicted percent of patients that have the condition: 0.09701492537313433\n","Actual percent of patients that have the condition: 0.11940298507462686\n","Accuracy: 0.9104477611940298\n","Precision: 0.6538461538461539\n","Recall: 0.53125\n","F1 Score: 0.5862068965517242\n","AUC: 0.9267081567796609\n","\n","[1]-gram CNN for Advanced.Lung.Disease\n","Training time: 9.621575355529785 seconds\n","Predicted percent of patients that have the condition: 0.0\n","Actual percent of patients that have the condition: 0.10820895522388059\n","Accuracy: 0.8917910447761194\n","Precision: 0.0\n","Recall: 0.0\n","F1 Score: 0.0\n","AUC: 0.8805367190881547\n","\n","[1, 2]-gram CNN for Advanced.Lung.Disease\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Training time: 23.60663151741028 seconds\n","Predicted percent of patients that have the condition: 0.014925373134328358\n","Actual percent of patients that have the condition: 0.10820895522388059\n","Accuracy: 0.8992537313432836\n","Precision: 0.75\n","Recall: 0.10344827586206896\n","F1 Score: 0.18181818181818182\n","AUC: 0.8865243110662242\n","\n","[1, 2, 3]-gram CNN for Advanced.Lung.Disease\n","Training time: 60.171048402786255 seconds\n","Predicted percent of patients that have the condition: 0.041044776119402986\n","Actual percent of patients that have the condition: 0.10820895522388059\n","Accuracy: 0.917910447761194\n","Precision: 0.8181818181818182\n","Recall: 0.3103448275862069\n","F1 Score: 0.45000000000000007\n","AUC: 0.9357957004761217\n","\n","[1, 2, 3, 4]-gram CNN for Advanced.Lung.Disease\n","Training time: 101.2346203327179 seconds\n","Predicted percent of patients that have the condition: 0.055970149253731345\n","Actual percent of patients that have the condition: 0.10820895522388059\n","Accuracy: 0.9253731343283582\n","Precision: 0.8\n","Recall: 0.41379310344827586\n","F1 Score: 0.5454545454545454\n","AUC: 0.9271389409897561\n","\n","[1, 2, 3, 4, 5]-gram CNN for Advanced.Lung.Disease\n","Training time: 132.43843460083008 seconds\n","Predicted percent of patients that have the condition: 0.0708955223880597\n","Actual percent of patients that have the condition: 0.10820895522388059\n","Accuracy: 0.917910447761194\n","Precision: 0.6842105263157895\n","Recall: 0.4482758620689655\n","F1 Score: 0.5416666666666666\n","AUC: 0.9149473380464579\n","\n","[2, 3, 4, 5]-gram CNN for Advanced.Lung.Disease\n","Training time: 123.31303572654724 seconds\n","Predicted percent of patients that have the condition: 0.06716417910447761\n","Actual percent of patients that have the condition: 0.10820895522388059\n","Accuracy: 0.914179104477612\n","Precision: 0.6666666666666666\n","Recall: 0.41379310344827586\n","F1 Score: 0.5106382978723404\n","AUC: 0.9274274996393017\n","\n","[1]-gram CNN for Chronic.Neurological.Dystrophies\n","Training time: 9.584951162338257 seconds\n","Predicted percent of patients that have the condition: 0.24253731343283583\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.7761194029850746\n","Precision: 0.4461538461538462\n","Recall: 0.5471698113207547\n","F1 Score: 0.4915254237288135\n","AUC: 0.7328652917946469\n","\n","[1, 2]-gram CNN for Chronic.Neurological.Dystrophies\n","Training time: 23.619812488555908 seconds\n","Predicted percent of patients that have the condition: 0.3208955223880597\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.7350746268656716\n","Precision: 0.3953488372093023\n","Recall: 0.6415094339622641\n","F1 Score: 0.4892086330935252\n","AUC: 0.7590171127687582\n","\n","[1, 2, 3]-gram CNN for Chronic.Neurological.Dystrophies\n","Training time: 60.18050980567932 seconds\n","Predicted percent of patients that have the condition: 0.018656716417910446\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.8134328358208955\n","Precision: 0.8\n","Recall: 0.07547169811320754\n","F1 Score: 0.13793103448275862\n","AUC: 0.7222465993856956\n","\n","[1, 2, 3, 4]-gram CNN for Chronic.Neurological.Dystrophies\n","Training time: 101.18965148925781 seconds\n","Predicted percent of patients that have the condition: 0.1044776119402985\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.8470149253731343\n","Precision: 0.7142857142857143\n","Recall: 0.37735849056603776\n","F1 Score: 0.4938271604938272\n","AUC: 0.7551557700745941\n","\n","[1, 2, 3, 4, 5]-gram CNN for Chronic.Neurological.Dystrophies\n","Training time: 132.48689484596252 seconds\n","Predicted percent of patients that have the condition: 0.17537313432835822\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.8283582089552238\n","Precision: 0.574468085106383\n","Recall: 0.5094339622641509\n","F1 Score: 0.54\n","AUC: 0.7533567354102677\n","\n","[2, 3, 4, 5]-gram CNN for Chronic.Neurological.Dystrophies\n","Training time: 123.29600143432617 seconds\n","Predicted percent of patients that have the condition: 0.332089552238806\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.7238805970149254\n","Precision: 0.38202247191011235\n","Recall: 0.6415094339622641\n","F1 Score: 0.47887323943661975\n","AUC: 0.6985081175954366\n","\n","[1]-gram CNN for Chronic.Pain.Fibromyalgia\n","Training time: 9.562490940093994 seconds\n","Predicted percent of patients that have the condition: 0.014925373134328358\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.8097014925373134\n","Precision: 0.75\n","Recall: 0.05660377358490566\n","F1 Score: 0.10526315789473685\n","AUC: 0.6430890741553313\n","\n","[1, 2]-gram CNN for Chronic.Pain.Fibromyalgia\n","Training time: 23.610628366470337 seconds\n","Predicted percent of patients that have the condition: 0.048507462686567165\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.7985074626865671\n","Precision: 0.46153846153846156\n","Recall: 0.11320754716981132\n","F1 Score: 0.18181818181818182\n","AUC: 0.7009214567792892\n","\n","[1, 2, 3]-gram CNN for Chronic.Pain.Fibromyalgia\n","Training time: 60.13580918312073 seconds\n","Predicted percent of patients that have the condition: 0.3619402985074627\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.7313432835820896\n","Precision: 0.4020618556701031\n","Recall: 0.7358490566037735\n","F1 Score: 0.52\n","AUC: 0.7505046072838965\n","\n","[1, 2, 3, 4]-gram CNN for Chronic.Pain.Fibromyalgia\n","Training time: 101.14035320281982 seconds\n","Predicted percent of patients that have the condition: 0.08955223880597014\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.8395522388059702\n","Precision: 0.7083333333333334\n","Recall: 0.32075471698113206\n","F1 Score: 0.44155844155844154\n","AUC: 0.8017551557700746\n","\n","[1, 2, 3, 4, 5]-gram CNN for Chronic.Pain.Fibromyalgia\n","Training time: 132.3774130344391 seconds\n","Predicted percent of patients that have the condition: 0.06343283582089553\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.8507462686567164\n","Precision: 0.8823529411764706\n","Recall: 0.2830188679245283\n","F1 Score: 0.4285714285714286\n","AUC: 0.8238262395787627\n","\n","[2, 3, 4, 5]-gram CNN for Chronic.Pain.Fibromyalgia\n","Training time: 123.31846809387207 seconds\n","Predicted percent of patients that have the condition: 0.17164179104477612\n","Actual percent of patients that have the condition: 0.19776119402985073\n","Accuracy: 0.8246268656716418\n","Precision: 0.5652173913043478\n","Recall: 0.49056603773584906\n","F1 Score: 0.5252525252525252\n","AUC: 0.8153576129881527\n","\n","[1]-gram CNN for Alcohol.Abuse\n","Training time: 9.579637050628662 seconds\n","Predicted percent of patients that have the condition: 0.10820895522388059\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.917910447761194\n","Precision: 0.5862068965517241\n","Recall: 0.6296296296296297\n","F1 Score: 0.6071428571428571\n","AUC: 0.9231596741970186\n","\n","[1, 2]-gram CNN for Alcohol.Abuse\n","Training time: 23.609325408935547 seconds\n","Predicted percent of patients that have the condition: 0.03731343283582089\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.9365671641791045\n","Precision: 1.0\n","Recall: 0.37037037037037035\n","F1 Score: 0.5405405405405406\n","AUC: 0.9056400799139388\n","\n","[1, 2, 3]-gram CNN for Alcohol.Abuse\n","Training time: 60.124550580978394 seconds\n","Predicted percent of patients that have the condition: 0.1044776119402985\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.9514925373134329\n","Precision: 0.75\n","Recall: 0.7777777777777778\n","F1 Score: 0.7636363636363638\n","AUC: 0.9113262640233594\n","\n","[1, 2, 3, 4]-gram CNN for Alcohol.Abuse\n","Training time: 101.1268265247345 seconds\n","Predicted percent of patients that have the condition: 0.041044776119402986\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.9402985074626866\n","Precision: 1.0\n","Recall: 0.4074074074074074\n","F1 Score: 0.5789473684210525\n","AUC: 0.9062548025203626\n","\n","[1, 2, 3, 4, 5]-gram CNN for Alcohol.Abuse\n","Training time: 132.54582715034485 seconds\n","Predicted percent of patients that have the condition: 0.09328358208955224\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.9626865671641791\n","Precision: 0.84\n","Recall: 0.7777777777777778\n","F1 Score: 0.8076923076923077\n","AUC: 0.9082526509912402\n","\n","[2, 3, 4, 5]-gram CNN for Alcohol.Abuse\n","Training time: 123.31580829620361 seconds\n","Predicted percent of patients that have the condition: 0.08582089552238806\n","Actual percent of patients that have the condition: 0.10074626865671642\n","Accuracy: 0.9552238805970149\n","Precision: 0.8260869565217391\n","Recall: 0.7037037037037037\n","F1 Score: 0.76\n","AUC: 0.900568618410942\n","\n","[1]-gram CNN for Other.Substance.Abuse\n","Training time: 9.581738471984863 seconds\n","Predicted percent of patients that have the condition: 0.0\n","Actual percent of patients that have the condition: 0.1044776119402985\n","Accuracy: 0.8955223880597015\n","Precision: 0.0\n","Recall: 0.0\n","F1 Score: 0.0\n","AUC: 0.8952380952380953\n","\n","[1, 2]-gram CNN for Other.Substance.Abuse\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Training time: 23.615981340408325 seconds\n","Predicted percent of patients that have the condition: 0.011194029850746268\n","Actual percent of patients that have the condition: 0.1044776119402985\n","Accuracy: 0.9067164179104478\n","Precision: 1.0\n","Recall: 0.10714285714285714\n","F1 Score: 0.19354838709677416\n","AUC: 0.9105654761904762\n","\n","[1, 2, 3]-gram CNN for Other.Substance.Abuse\n","Training time: 60.13122582435608 seconds\n","Predicted percent of patients that have the condition: 0.029850746268656716\n","Actual percent of patients that have the condition: 0.1044776119402985\n","Accuracy: 0.9104477611940298\n","Precision: 0.75\n","Recall: 0.21428571428571427\n","F1 Score: 0.3333333333333333\n","AUC: 0.9208333333333333\n","\n","[1, 2, 3, 4]-gram CNN for Other.Substance.Abuse\n","Training time: 101.16284942626953 seconds\n","Predicted percent of patients that have the condition: 0.033582089552238806\n","Actual percent of patients that have the condition: 0.1044776119402985\n","Accuracy: 0.9216417910447762\n","Precision: 0.8888888888888888\n","Recall: 0.2857142857142857\n","F1 Score: 0.43243243243243246\n","AUC: 0.9030505952380953\n","\n","[1, 2, 3, 4, 5]-gram CNN for Other.Substance.Abuse\n","Training time: 132.37155318260193 seconds\n","Predicted percent of patients that have the condition: 0.19029850746268656\n","Actual percent of patients that have the condition: 0.1044776119402985\n","Accuracy: 0.8843283582089553\n","Precision: 0.47058823529411764\n","Recall: 0.8571428571428571\n","F1 Score: 0.6075949367088607\n","AUC: 0.9108630952380953\n","\n","[2, 3, 4, 5]-gram CNN for Other.Substance.Abuse\n","Training time: 123.3088915348053 seconds\n","Predicted percent of patients that have the condition: 0.055970149253731345\n","Actual percent of patients that have the condition: 0.1044776119402985\n","Accuracy: 0.9216417910447762\n","Precision: 0.7333333333333333\n","Recall: 0.39285714285714285\n","F1 Score: 0.5116279069767441\n","AUC: 0.9174107142857143\n","\n","[1]-gram CNN for Obesity\n","Training time: 9.590898752212524 seconds\n","Predicted percent of patients that have the condition: 0.0\n","Actual percent of patients that have the condition: 0.04477611940298507\n","Accuracy: 0.9552238805970149\n","Precision: 0.0\n","Recall: 0.0\n","F1 Score: 0.0\n","AUC: 0.6969401041666667\n","\n","[1, 2]-gram CNN for Obesity\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Training time: 23.621701955795288 seconds\n","Predicted percent of patients that have the condition: 0.0\n","Actual percent of patients that have the condition: 0.04477611940298507\n","Accuracy: 0.9552238805970149\n","Precision: 0.0\n","Recall: 0.0\n","F1 Score: 0.0\n","AUC: 0.6982421875\n","\n","[1, 2, 3]-gram CNN for Obesity\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Training time: 60.182400941848755 seconds\n","Predicted percent of patients that have the condition: 0.007462686567164179\n","Actual percent of patients that have the condition: 0.04477611940298507\n","Accuracy: 0.9552238805970149\n","Precision: 0.5\n","Recall: 0.08333333333333333\n","F1 Score: 0.14285714285714285\n","AUC: 0.6500651041666667\n","\n","[1, 2, 3, 4]-gram CNN for Obesity\n","Training time: 101.12406587600708 seconds\n","Predicted percent of patients that have the condition: 0.0\n","Actual percent of patients that have the condition: 0.04477611940298507\n","Accuracy: 0.9552238805970149\n","Precision: 0.0\n","Recall: 0.0\n","F1 Score: 0.0\n","AUC: 0.7464192708333333\n","\n","[1, 2, 3, 4, 5]-gram CNN for Obesity\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Training time: 132.45684266090393 seconds\n","Predicted percent of patients that have the condition: 0.0\n","Actual percent of patients that have the condition: 0.04477611940298507\n","Accuracy: 0.9552238805970149\n","Precision: 0.0\n","Recall: 0.0\n","F1 Score: 0.0\n","AUC: 0.814453125\n","\n","[2, 3, 4, 5]-gram CNN for Obesity\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Training time: 123.31896090507507 seconds\n","Predicted percent of patients that have the condition: 0.0\n","Actual percent of patients that have the condition: 0.04477611940298507\n","Accuracy: 0.9552238805970149\n","Precision: 0.0\n","Recall: 0.0\n","F1 Score: 0.0\n","AUC: 0.8082682291666667\n","\n","[1]-gram CNN for Schizophrenia.and.other.Psychiatric.Disorders\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Training time: 9.585261821746826 seconds\n","Predicted percent of patients that have the condition: 0.0\n","Actual percent of patients that have the condition: 0.17164179104477612\n","Accuracy: 0.8283582089552238\n","Precision: 0.0\n","Recall: 0.0\n","F1 Score: 0.0\n","AUC: 0.8532119075597336\n","\n","[1, 2]-gram CNN for Schizophrenia.and.other.Psychiatric.Disorders\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Training time: 23.595029592514038 seconds\n","Predicted percent of patients that have the condition: 0.0708955223880597\n","Actual percent of patients that have the condition: 0.17164179104477612\n","Accuracy: 0.8768656716417911\n","Precision: 0.8421052631578947\n","Recall: 0.34782608695652173\n","F1 Score: 0.49230769230769234\n","AUC: 0.8668233450842147\n","\n","[1, 2, 3]-gram CNN for Schizophrenia.and.other.Psychiatric.Disorders\n","Training time: 60.09175252914429 seconds\n","Predicted percent of patients that have the condition: 0.10820895522388059\n","Actual percent of patients that have the condition: 0.17164179104477612\n","Accuracy: 0.8917910447761194\n","Precision: 0.7931034482758621\n","Recall: 0.5\n","F1 Score: 0.6133333333333334\n","AUC: 0.8530650215432825\n","\n","[1, 2, 3, 4]-gram CNN for Schizophrenia.and.other.Psychiatric.Disorders\n","Training time: 101.11079239845276 seconds\n","Predicted percent of patients that have the condition: 0.029850746268656716\n","Actual percent of patients that have the condition: 0.17164179104477612\n","Accuracy: 0.8582089552238806\n","Precision: 1.0\n","Recall: 0.17391304347826086\n","F1 Score: 0.29629629629629634\n","AUC: 0.8600665883274579\n","\n","[1, 2, 3, 4, 5]-gram CNN for Schizophrenia.and.other.Psychiatric.Disorders\n","Training time: 132.38000679016113 seconds\n","Predicted percent of patients that have the condition: 0.014925373134328358\n","Actual percent of patients that have the condition: 0.17164179104477612\n","Accuracy: 0.8432835820895522\n","Precision: 1.0\n","Recall: 0.08695652173913043\n","F1 Score: 0.16\n","AUC: 0.8448883666274971\n","\n","[2, 3, 4, 5]-gram CNN for Schizophrenia.and.other.Psychiatric.Disorders\n","Training time: 123.32072162628174 seconds\n","Predicted percent of patients that have the condition: 0.03731343283582089\n","Actual percent of patients that have the condition: 0.17164179104477612\n","Accuracy: 0.8582089552238806\n","Precision: 0.9\n","Recall: 0.1956521739130435\n","F1 Score: 0.3214285714285714\n","AUC: 0.8299059929494712\n","\n","[1]-gram CNN for Depression\n","Training time: 9.573947668075562 seconds\n","Predicted percent of patients that have the condition: 0.30970149253731344\n","Actual percent of patients that have the condition: 0.30970149253731344\n","Accuracy: 0.917910447761194\n","Precision: 0.8674698795180723\n","Recall: 0.8674698795180723\n","F1 Score: 0.8674698795180723\n","AUC: 0.9249104526212959\n","\n","[1, 2]-gram CNN for Depression\n","Training time: 23.604054927825928 seconds\n","Predicted percent of patients that have the condition: 0.0708955223880597\n","Actual percent of patients that have the condition: 0.30970149253731344\n","Accuracy: 0.7611940298507462\n","Precision: 1.0\n","Recall: 0.2289156626506024\n","F1 Score: 0.37254901960784315\n","AUC: 0.9435363073917291\n","\n","[1, 2, 3]-gram CNN for Depression\n","Training time: 60.13808822631836 seconds\n","Predicted percent of patients that have the condition: 0.055970149253731345\n","Actual percent of patients that have the condition: 0.30970149253731344\n","Accuracy: 0.746268656716418\n","Precision: 1.0\n","Recall: 0.18072289156626506\n","F1 Score: 0.30612244897959184\n","AUC: 0.8916965157929012\n","\n","[1, 2, 3, 4]-gram CNN for Depression\n","Training time: 101.07524800300598 seconds\n","Predicted percent of patients that have the condition: 0.20149253731343283\n","Actual percent of patients that have the condition: 0.30970149253731344\n","Accuracy: 0.8544776119402985\n","Precision: 0.9074074074074074\n","Recall: 0.5903614457831325\n","F1 Score: 0.7153284671532847\n","AUC: 0.9004884402474763\n","\n","[1, 2, 3, 4, 5]-gram CNN for Depression\n","Training time: 132.37443113327026 seconds\n","Predicted percent of patients that have the condition: 0.014925373134328358\n","Actual percent of patients that have the condition: 0.30970149253731344\n","Accuracy: 0.7052238805970149\n","Precision: 1.0\n","Recall: 0.04819277108433735\n","F1 Score: 0.09195402298850576\n","AUC: 0.8593943340931292\n","\n","[2, 3, 4, 5]-gram CNN for Depression\n","Training time: 123.30119943618774 seconds\n","Predicted percent of patients that have the condition: 0.041044776119402986\n","Actual percent of patients that have the condition: 0.30970149253731344\n","Accuracy: 0.7238805970149254\n","Precision: 0.9090909090909091\n","Recall: 0.12048192771084337\n","F1 Score: 0.21276595744680848\n","AUC: 0.7361120156300879\n","\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}